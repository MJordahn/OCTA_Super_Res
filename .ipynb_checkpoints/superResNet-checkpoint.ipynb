{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SRResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# HELPER FUNCTIONS TO BE USED DURING TRAINING\n",
    "import DataLoader\n",
    "from DataLoader import MabulaDataset\n",
    "from albumentations import Flip, Rotate, RandomCrop\n",
    "from albumentations.pytorch import ToTensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from SRResNetBlock import *\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from Utility import *\n",
    "\n",
    "##########################################################\n",
    "############### Model creation ###########################\n",
    "\n",
    "def create_model(dim=320, scale_factor=2, batch_size=1, n_res_blocks=8, GPU=True):   \n",
    "    t = transformationMatrix(dim, scale_factor, batch_size, GPU=GPU)[0,0]\n",
    "    net = SRResNet(scale_factor=scale_factor, n_res_blocks=n_res_blocks)\n",
    "    discriminator = SRResNetDiscriminator()\n",
    "    \n",
    "    # move models to GPU, if available\n",
    "    if torch.cuda.is_available() and GPU:\n",
    "        net.to(torch.device(\"cuda:0\"))\n",
    "        discriminator.to(torch.device(\"cuda:0\"))\n",
    "        print('Models moved to GPU.')\n",
    "    else:\n",
    "        print('Only CPU available.')\n",
    "    return net, t\n",
    "\n",
    "##########################################################\n",
    "############### Training loop ############################\n",
    "\n",
    "def training_loop(net, optimizer, dataloaders, t, n_epochs=1000, GPU=True):\n",
    "    train_loader, test_loader = dataloaders\n",
    "    \n",
    "    print_every= 10\n",
    "    test_every = 20\n",
    "    \n",
    "    # keep track of losses over time\n",
    "    losses = []\n",
    "    meanPSNR_lst = []\n",
    "    meanSSIM_lst = []\n",
    "    for epoch in range(n_epochs+1):      \n",
    "        for batch in train_loader:\n",
    "            X_hr_true = batch['image']\n",
    "            if torch.cuda.is_available() and GPU:\n",
    "                X_hr_true = X_hr_true.to(\"cuda:0\")\n",
    "            X_lr = torch.matmul(t, X_hr_true)\n",
    "            # =========================================\n",
    "            #            TRAIN Network\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            X_hr_fake = net(X_lr)\n",
    "            MSE_loss = nn.MSELoss()(X_hr_fake, X_hr_true)\n",
    "            MSE_loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        has_tested = False\n",
    "        if epoch % test_every == 0:\n",
    "            print(\"#### Testing \", epoch, \" ####\")\n",
    "            net.eval()\n",
    "            PSNR_lst = []\n",
    "            SSIM_lst = []\n",
    "            for batch in test_loader:\n",
    "                X_hr_true = batch['image']\n",
    "                if torch.cuda.is_available() and GPU:\n",
    "                    X_hr_true = X_hr_true.to(\"cuda:0\")\n",
    "                X_lr = torch.matmul(t, X_hr_true)\n",
    "                with torch.no_grad():\n",
    "                    X_hr_fake = net(X_lr)\n",
    "                    MSE_loss_test = nn.MSELoss()(X_hr_fake, X_hr_true)\n",
    "                X_hr_fake = X_hr_fake.cpu()\n",
    "                X_hr_true =  X_hr_true.cpu()\n",
    "                PSNR, SSIM = calculate_scores(X_hr_fake, X_hr_true)\n",
    "                PSNR_lst.append(PSNR)\n",
    "                SSIM_lst.append(SSIM)\n",
    "            meanPSNR = np.mean(PSNR_lst)\n",
    "            meanSSIM = np.mean(SSIM_lst)\n",
    "            meanPSNR_lst.append(meanPSNR)\n",
    "            meanSSIM_lst.append(meanSSIM)\n",
    "            net.train()\n",
    "            has_tested = True\n",
    "        \n",
    "        # Logging info\n",
    "        if epoch % print_every == 0 and has_tested:\n",
    "            print(\"---- Epoch nr: \", epoch, \" ----\")\n",
    "            print(\"Train loss: \", str(MSE_loss))\n",
    "            print(\"Last Test loss: \", str(MSE_loss_test))\n",
    "            print(\"Last PSNR: \", meanPSNR)\n",
    "            print(\"Last SSIM: \", meanSSIM)\n",
    "            losses.append((MSE_loss.item(), MSE_loss_test.item())) \n",
    "             \n",
    "    print(\"Done\")\n",
    "    return losses, meanPSNR_lst, meanSSIM_lst\n",
    "\n",
    "##########################################################\n",
    "############### Training Multiple models #################\n",
    "\n",
    "def trainModelEnsemble(name=\"name\", n_epochs=100, dim=320, scale_factors = [2, 4, 8], batch_size=16, n_res_blocks=8, GPU=True):\n",
    "    # Records losses of the trained models\n",
    "    loss_dict = {}\n",
    "    # Trains a model for each stride:\n",
    "    for _, scale_factor in enumerate(scale_factors):\n",
    "        # Define data loaders:\n",
    "        train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "        test_loader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "        dataloaders = [train_loader, test_loader]\n",
    "\n",
    "        # Create model:\n",
    "        net, t = create_model(dim=dim, scale_factor=scale_factor, batch_size=batch_size, GPU=GPU, n_res_blocks=n_res_blocks)\n",
    "\n",
    "        # Define optimizers:\n",
    "        optimizer = optim.Adam(net.parameters(), lr, [beta1, beta2])\n",
    "\n",
    "        print(\"\\n --- Training with parameters: ---\")\n",
    "        print(\"scale factor: \", scale_factor)\n",
    "        print(\"epochs: \", n_epochs)\n",
    "        print(\"batch size: \", batch_size)\n",
    "            \n",
    "        # Train model:\n",
    "        losses, meanPSNR_lst, meanSSIM_lst = training_loop(net, optimizer, dataloaders, t, n_epochs=n_epochs, GPU=GPU)\n",
    "        loss_dict[name + \"_\" + str(scale_factor)] = (losses, meanPSNR_lst, meanSSIM_lst)\n",
    "            \n",
    "        # Save trained model:\n",
    "        path = \"checkpoints/\" + name + \"_\" + str(scale_factor)\n",
    "        saveModels(net, net, path=path)\n",
    "\n",
    "        # Delete the trained models\n",
    "        del net\n",
    "        print(\"Passed training of model: \", name+str(scale_factor))\n",
    "        print(\"\\n\")\n",
    "\n",
    "    return loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU = True\n",
    "dim = 320\n",
    "batch_size = 4\n",
    "n_res_blocks = 6\n",
    "n_epochs = 600\n",
    "scale_factors = [2, 4, 8]\n",
    "# Parameters of optimizer:\n",
    "lr = 0.0001\n",
    "beta1 = 0.5\n",
    "beta2 = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose augmentations:\n",
    "transforms=[Flip(), Rotate(), ToTensor()]\n",
    "test_transforms=[ToTensor()]\n",
    "# Create dataset:\n",
    "train_data = MabulaDataset(file_path=\"/Data/OCTA/Train\", transforms=transforms)\n",
    "test_data = MabulaDataset(file_path=\"/Data/OCTA/Test\", transforms=test_transforms)\n",
    "# Create dataloader:\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "# Clamp loaders\n",
    "dataloaders = [train_loader, test_loader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SRResNet\n",
    "#loss_dict = trainModelEnsemble(name=\"SRResNet\",\n",
    "#                               n_epochs=n_epochs,\n",
    "#                               dim=dim,\n",
    "#                               batch_size=batch_size,\n",
    "#                               n_res_blocks=n_res_blocks,\n",
    "#                               scale_factors=scale_factors,\n",
    "#                               GPU=GPU)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
